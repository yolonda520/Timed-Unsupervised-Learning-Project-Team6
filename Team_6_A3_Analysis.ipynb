{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<font size = \"5 \"> Unsupervised Learning Project </font> <br/>\n",
    "\n",
    "<b> Assignment 3 </b> <br>\n",
    "\n",
    "<p> DAT-5303 | Machine Learning </p>\n",
    "\n",
    "<p> Cohort: Valencia 5 </p>\n",
    "\n",
    "<b> Created By: (Team 6) </b> <br>\n",
    "\n",
    "<i> Jorge Andrés Betancourt Enríquez </i> <br>\n",
    "<i> Yu Huang </i> <br>\n",
    "<i> Akhilkumar Mishra <i/> <br>\n",
    "<i> Mouhamet Ndiaye <i/> <br>\n",
    "<i> pattamaphon sukcharoen <i/> <br>\n",
    "<i> Harsh Teckchandani <i/> <br>\n",
    "\n",
    "<b> Hult International Business School</b> <br>\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h1> Part I: Fundamental Dataset Exploration </h1><br>\n",
    "\n",
    "***\n",
    "\n",
    "<h2> Import libraries, Load Data and Define Functions </h2><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Import Packages\n",
    "##############################################################################\n",
    "\n",
    "import pandas                        as pd                        # data science essentials\n",
    "import matplotlib.pyplot             as plt                       # fundamental data visualization\n",
    "import seaborn                       as sns                       # enhanced visualization\n",
    "from sklearn.preprocessing           import StandardScaler        # standard scaler\n",
    "from sklearn.decomposition           import PCA                   # Principal component analysis\n",
    "from scipy.cluster.hierarchy         import dendrogram, linkage   # dendrograms\n",
    "from sklearn.cluster                 import KMeans                # k-means clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Load Data\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "# Reading in the dataset.\n",
    "survey_data = pd.read_excel(io = \"Survey_Data_Final_Exam.xlsx\")\n",
    "\n",
    "\n",
    "# setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# User-Defined Functions\n",
    "############################################################################\n",
    "\n",
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xlim(0,10)\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()\n",
    "    \n",
    "########################################\n",
    "# Inertia Plot\n",
    "########################################\n",
    "\n",
    "def interia_plot(data, max_clust = 50):\n",
    "    \n",
    "    ks       = range(1, max_clust)\n",
    "    inertias = []\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        # INSTANTIATING a kmeans object\n",
    "        model = KMeans(n_clusters = k)\n",
    "\n",
    "\n",
    "        # FITTING to the data\n",
    "        model.fit(data)\n",
    "\n",
    "\n",
    "        # append each inertia to the list of inertias\n",
    "        inertias.append(model.inertia_)\n",
    "\n",
    "\n",
    "\n",
    "    # plotting ks vs inertias\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    plt.plot(ks, inertias, '-o')\n",
    "\n",
    "\n",
    "    # labeling and displaying the plot\n",
    "    plt.xlabel('number of clusters, k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.xticks(ks)\n",
    "    plt.show() \n",
    "\n",
    "    \n",
    "########################################\n",
    "# Split ID\n",
    "########################################    \n",
    "    \n",
    "def split_id(col, df, new_col_name=\"id_new\"):\n",
    "    \"\"\"\n",
    "    Split the value of a string in series(column of DataFrame), and sum of the number of result items.\n",
    "    Automatically append summed column into original DataFrame.\n",
    "    Parameter:\n",
    "    --------------\n",
    "    col: The column need to be splited\n",
    "    df:  DataFrame where column is located\n",
    "    sep: split by , default ''\n",
    "    new_col_name: the name of new column after summing split, default 'id_new'\n",
    "    --------------\n",
    "    \"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = df.loc[index, col][1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2> Exploratory Data Analysis </h2><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This part is created to get a sense of the data by running some standard functions \n",
    "- All the variables had the correct datatypes 7 object columns and 73 Integer\n",
    "- 392 rows (response) and 79 columns \n",
    "- There are 3 Questions in the survey that are repeated\n",
    "- demographic information related to each person is as follows: </br>\n",
    "<br><br>\n",
    "  * surveyID\n",
    "  * What laptop do you currently have?\n",
    "  * What laptop would you buy in next assuming if all laptops cost the same?\n",
    "  * What program are you in?\n",
    "  * What is your age?\n",
    "  * Gender\n",
    "  * What is your nationality?\n",
    "  * What is your ethnicity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Data Understanding\n",
    "# #############################################################################\n",
    "\n",
    "## Column names\n",
    "\n",
    "# print(survey_data.columns)\n",
    "\n",
    "# # displaying the first rows of the DataFrame\n",
    "\n",
    "# survey_data.head(n = 5)\n",
    "\n",
    "#survey_data.shape\n",
    "\n",
    "# ############################################################################\n",
    "# Inforrmation about each variable\n",
    "# ############################################################################\n",
    "\n",
    "## Display general information about each variable, including types and number of non-missing values.\n",
    "\n",
    "#survey_data.info()\n",
    "\n",
    "## descriptive statistics\n",
    "\n",
    "#survey_data.iloc[:, 1: ].describe().round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2> Data manipulation </h2><br>\n",
    "\n",
    "***\n",
    "\n",
    "<h3> columns: name modification </h3><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.rename(columns = \n",
    "                   {\n",
    "                              'surveyID'                                                                  :'ID',\n",
    "                              'Am the life of the party'                                                  :'life of party',\n",
    "                              'Feel little concern for others'                                            :'little concern for others',\n",
    "                              'Am always prepared'                                                        :'always prepared',\n",
    "                              'Get stressed out easily'                                                   :'easily streesed out',\n",
    "                              'Have a rich vocabulary'                                                    :'rich vocabulary',\n",
    "                              \"Don't talk a lot\"                                                          :'quiet person',\n",
    "                              'Am interested in people'                                                   :'inrested in people',\n",
    "                              'Leave my belongings around'                                                :'forgetful',\n",
    "                              'Am relaxed most of the time'                                               :'mostly relaxed',\n",
    "                              'Have difficulty understanding abstract ideas'                              :'struggle with abstract ideas',\n",
    "                              'Feel comfortable around people'                                            :'comfortable around people',\n",
    "                              'Have a vivid imagination'                                                  :'imaginative',\n",
    "                              'Am not interested in abstract ideas'                                       :'not interested in abstract ideas',\n",
    "                              \"Am not interested in other people's problems\"                              :'not empathic',\n",
    "                              'Have little to say'                                                        :'speechless',\n",
    "                              'Have a soft heart'                                                         :'soft heart',\n",
    "                              'Often forget to put things back in their proper place'                     :'disorganized',\n",
    "                              'Talk to a lot of different people at parties'                              :'talkative',\n",
    "                              'Am not really interested in others'                                        :'not inrested in others', # Could be the same understanding as the 15th question \n",
    "                              'Am quick to understand things'                                             :'fast learner',\n",
    "                              \"Don't mind being the center of attention\"                                  :'being popular',\n",
    "                              'See underlying patterns in complex situations'                             :'understand complex situations',\n",
    "                              \"Don't  generate ideas that are new and different\"                          :'lack of new ideas',\n",
    "                              'Work well with people from diverse cultural backgrounds'                   :'work well with diverse people',\n",
    "                              'Effectively negotiate interests, resources, and roles'                     :'good negotiatiator',\n",
    "                              \"Can't rally people on the team around a common goal\"                       :\"can't encourage people in the team\",\n",
    "                              'Translate ideas into plans that are organized and realistic'               :'translate ideas into plans',\n",
    "                              'What laptop do you currently have?'                                        :'current laptop',\n",
    "                              'What laptop would you buy in next assuming if all laptops cost the same?'  :'future laptop',\n",
    "                              'What program are you in?'                                                  :'study program',\n",
    "                              'What is your age?'                                                         :'age',\n",
    "                              'What is your nationality? '                                                :'nationality',\n",
    "                              'What is your ethnicity?'                                                   :'ethnicity'\n",
    "                       \n",
    "                   },\n",
    "                   inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## check that the columns have changed\n",
    "\n",
    "##  New Column names \n",
    "#print(survey_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h3> Missing Value Analysis and Imputation</h3><br>\n",
    "\n",
    "***\n",
    "\n",
    "- For the missing value imputation we first need to see the total number of missing values per column\n",
    "- According to the output there is just one missing value related with ethnicity\n",
    "- Therefore the process that can be apply is to fill the empty rows with 'Unknown', also if is required in future manipulation data that present any error will be change to 'Unknown'\n",
    "- Fill in missing values for 'ethnicity' with an appropriate value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_data.isnull().sum() # Total number of missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an imputation value (through soft-coding)\n",
    "\n",
    "# Filling the 'ethnicity' with 'Unknown'           '\n",
    "\n",
    "fill = \"unknown\"\n",
    "\n",
    "# imputing 'FAMILY_NAME' Unknown in the dataframe\n",
    "survey_data['ethnicity'] = survey_data['ethnicity'].fillna(fill)\n",
    "\n",
    "# survey_data.isnull().sum().sum() # Total number of missing in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h3> Nationality curation </h3><br>\n",
    "\n",
    "***\n",
    "\n",
    "- In order to see the most frequent nationalities this part is created to correct all the typos from the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to lower the object types\n",
    "\n",
    "survey_data['nationality']  = survey_data['nationality'].str.lower()\n",
    "\n",
    "#survey_data.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Looping over each nationality to print with a (,)\n",
    "# for name in survey_data['nationality']:\n",
    "#                    print(f\"'{name}',\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nationality Dictionary\n",
    "\n",
    "nationality_dic = {\n",
    "                    'caribbean-american'    :'american',\n",
    "                    'usa'                   :'american',\n",
    "                    'belgium'               :'belgian',\n",
    "                    'belgian '              :'belgian',\n",
    "                    'brazil'                :'brazilian',\n",
    "                    'english'               :'british',\n",
    "                    'british, indian'       :'british',\n",
    "                    'canada'                :'canadian',\n",
    "                    'china'                 :'chinese',\n",
    "                    'colombia'              :'colombian',\n",
    "                    'congolese'             :'congolese (dr congo)',\n",
    "                    'costa rica'            :'costa rican',\n",
    "                    'costarrican'           :'costa rican',\n",
    "                    'czech republic'        :'czech',\n",
    "                    'dominican '            :'dominican',\n",
    "                    'dominican republic'    :'dominican',\n",
    "                    'ecuador'               :'ecuadorian',\n",
    "                    'filipino '             :'filipino',\n",
    "                    'philippines'           :'filipino',\n",
    "                    'french/ brazilian'     :'french',\n",
    "                    'germany'               :'german',\n",
    "                    'german/american'       :'german',\n",
    "                    'indian.'               :'indian',\n",
    "                    'india'                 :'indian',\n",
    "                    'indonesia'             :'indonesian',\n",
    "                    'italian and spanish'   :'italian',\n",
    "                    'mexico'                :'mexican',\n",
    "                    'nigeria'               :'nigerian',\n",
    "                    'dutch'                 :'norwegian',\n",
    "                    'peru'                  :'peruvian',\n",
    "                    'poland'                :'polish',\n",
    "                    'russia'                :'russian',\n",
    "                    'spain'                 :'spanish',\n",
    "                    'republic of korea'     :'south korea',\n",
    "                    'korea'                 :'south korea',\n",
    "                    'korean'                :'south korea',\n",
    "                    'taiwan( r.o.c)'        :'taiwan',\n",
    "                    'thailand'              :'thai',\n",
    "                    'venezuela'             :'venezuelan',\n",
    "                    '.'                     :'unknown',\n",
    "                    'calm'                  :'unknown',\n",
    "                    'hispanic '             :'unknown',\n",
    "                    'multi-ethnic'          :'unknown',\n",
    "                    'prefer not to answer'  :'unknown'\n",
    "\n",
    "} # Closing the Dictionary\n",
    "\n",
    "\n",
    "# replacing nationality values\n",
    "survey_data['nationality'].replace(nationality_dic, \n",
    "                                 inplace=True)\n",
    "\n",
    "# Counting the final values\n",
    "#survey_data['nationality'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h3> Duplicate Questions Analysis </h3><br>\n",
    "\n",
    "***\n",
    "\n",
    "<br> - The dataset has 3 duplicate Question: </br>\n",
    "\n",
    "\n",
    " * Take initiative even when circumstances, objectives, or rules aren't clear\n",
    " * Encourage direct and open discussions\n",
    " * Respond effectively to multiple priorities\n",
    " \n",
    "<br> - Because the answer consists of a scale from 1 to 5, here we want to calculate the difference between the response of the same question, therefore we create a new column for each question with the numerical difference </br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a new column to see the difference in the response for the first duplicate question\n",
    "survey_data[\"Take Initiative\"] = survey_data[\"Take initiative even when circumstances, objectives, or rules aren't clear\"] - survey_data[\"Take initiative even when circumstances, objectives, or rules aren't clear.1\"]      \n",
    "\n",
    "# Creating a new column to see the difference in the response for the second duplicate question\n",
    "survey_data[\"Encourage Discussions\"] = survey_data[\"Encourage direct and open discussions\"] - survey_data[\"Encourage direct and open discussions.1\"]      \n",
    "\n",
    "# Creating a new column to see the difference in the response for the third duplicate question\n",
    "survey_data[\"Respond effectively\"] = survey_data[\"Respond effectively to multiple priorities\"] - survey_data[\"Respond effectively to multiple priorities.1\"]  \n",
    "\n",
    "\n",
    "#survey_data.head()     \n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Counting the total responses that have difference for each of the three questions \n",
    "\n",
    "# print(f\"\"\"\n",
    "# Take Initiative\n",
    "# -------------\n",
    "# {survey_data[\"Take Initiative\"].value_counts()}\n",
    "\n",
    "\n",
    "# Encourage Discussions\n",
    "# -------------\n",
    "# {survey_data[\"Encourage Discussions\"].value_counts()}\n",
    "\n",
    "\n",
    "\n",
    "# Respond effectively\n",
    "# -------------\n",
    "# {survey_data[\"Respond effectively\"].value_counts()}\n",
    "      \n",
    "# \"\"\")\n",
    "\n",
    "# # ^ This allows us to look at the new colums and see how much the response differ between the duplicate questions\n",
    "\n",
    "############################################################################\n",
    "# Output\n",
    "############################################################################\n",
    "\n",
    "# Take Initiative\n",
    "# -------------\n",
    "#  0    325\n",
    "# -1     35\n",
    "#  1     22\n",
    "# -2      6\n",
    "#  2      2\n",
    "#  4      1\n",
    "#  3      1\n",
    "\n",
    "\n",
    "# Encourage Discussions\n",
    "# -------------\n",
    "#  0    321\n",
    "#  1     35\n",
    "# -1     24\n",
    "#  2      5\n",
    "# -2      4\n",
    "# -4      2\n",
    "#  3      1\n",
    "\n",
    "# Respond effectively\n",
    "# -------------\n",
    "#  0    308\n",
    "# -1     43\n",
    "#  1     27\n",
    "# -2     10\n",
    "#  2      4\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> - According to the numerical difference between the answers to the same question, we decided to proceed as follows: </br>\n",
    "\n",
    "* Drop the responses that have a numerical difference greater than 2\n",
    "\n",
    "* Taking into account the psychological point of view of the respondent, the answers that differ by one or two points come close to the initial idea of the respondent, this is an assumption that we include for the development of our model.\n",
    "\n",
    "* A numerical difference greater than 2 shows incongruity in the survey considering these people as outliers and proceeding to drop them from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the incongruent responses (Outliers)\n",
    "\n",
    "## Take initiative\n",
    "\n",
    "survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Take Initiative']== 4].index)\n",
    "survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Take Initiative']== 3].index)\n",
    "# survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Take Initiative']== -2].index)\n",
    "# survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Take Initiative']== 2].index)\n",
    "\n",
    "## Encourage Discussions\n",
    "\n",
    "survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Encourage Discussions']== -4].index)\n",
    "survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Encourage Discussions']== 3].index)\n",
    "# survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Encourage Discussions']== -2].index)\n",
    "# survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Encourage Discussions']== 2].index)\n",
    "\n",
    "## Respond effectively\n",
    "\n",
    "# survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Respond effectively']== -2].index)\n",
    "# survey_data = survey_data.drop(survey_data[survey_data.loc[:,'Respond effectively']== 2].index)\n",
    "\n",
    "# Checking the dataset shape after we drope the outliers\n",
    "#survey_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> - After our duplicate Questions Analysis we proceed as follows: </br>\n",
    "\n",
    " * From a psychological point of view, we decided to drop the second question, since it involves more thinking process from the respondent, regularly the first answer is closer to the feeling or idea that a person has when answering a certain question\n",
    " * Finally, we will drop the columns that were created in the previous step to avoid any noise in the analysis:\n",
    "   * Take Initiative\n",
    "   * Encourage Discussions\n",
    "   * Respond effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the duplicate column\n",
    "\n",
    "survey_data = survey_data.drop([\"Take initiative even when circumstances, objectives, or rules aren't clear.1\",\n",
    "                                'Encourage direct and open discussions.1',\n",
    "                                'Respond effectively to multiple priorities.1',\n",
    "                                'Take Initiative',\n",
    "                                'Encourage Discussions',\n",
    "                                'Respond effectively'],axis = 1)\n",
    "\n",
    "# survey_data.head()\n",
    "# survey_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the datsset after the curation\n",
    "survey_data.to_excel(\"Survey_Data_Final_Exam_Clean.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h1> Part II: Principal Component Analysis </h1><br>\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<h2> Column type modification </h2><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset.\n",
    "survey_df = pd.read_excel(io = \"Survey_Data_Final_Exam_Clean.xlsx\")\n",
    "\n",
    "# survey_df.head()\n",
    "# survey_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Gender Column\n",
    "############################################################################\n",
    "\n",
    "## Counting the total number of Male and Female in the survey\n",
    "#survey_df['Gender'].value_counts()\n",
    "\n",
    "# Dictionary to loop over Gender\n",
    "gender = {\n",
    "          'Male'    :1,\n",
    "          'Female'  :2\n",
    "         }\n",
    "\n",
    "# Changing from object to boolean the Gender column \n",
    "survey_df.Gender = [gender[item] for item in survey_df.Gender]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# current laptop Column\n",
    "############################################################################\n",
    "\n",
    "## Counting the total number of current Mackbooks and Windows laptops\n",
    "#survey_df['current laptop'].value_counts()\n",
    "\n",
    "\n",
    "# Dictionary to loop over current laptop\n",
    "current_laptop = {\n",
    "                  'Macbook'         :1,\n",
    "                  'MAC'             :1,\n",
    "                  'Windows laptop'  :2\n",
    "                  }\n",
    "\n",
    "# Changing from object to integer the current laptop column \n",
    "survey_df['current laptop'] = [current_laptop[item] for item in survey_df['current laptop']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# future laptop Column\n",
    "############################################################################\n",
    "\n",
    "## Counting the total number of future Mackbook and Windows laptops\n",
    "#survey_df['future laptop'].value_counts()\n",
    "\n",
    "\n",
    "# Dictionary to loop over future laptop\n",
    "\n",
    "future_laptop = {\n",
    "                 'Macbook'         :1,\n",
    "                 'MAC'             :1,\n",
    "                 'Windows laptop'  :2,\n",
    "                 'Chromebook'      :3\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "# Changing from object to integer the future laptop column\n",
    "survey_df['future laptop'] = [future_laptop[item] for item in survey_df['future laptop']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# study program Column\n",
    "############################################################################\n",
    "\n",
    "## Counting the total number of future Mackbook and Windows laptops\n",
    "#survey_df['study program'].value_counts()\n",
    "\n",
    "\n",
    "# Dictionary to loop over study program\n",
    "\n",
    "study_program = {\n",
    "                 'DD (MIB & Business Analytics)'     :1,\n",
    "                 'One year Business Analytics'       :2,\n",
    "                 'DD (MBA & Business Analytics)'     :3,\n",
    "                 'DD (MBA & Disruptive innovation)'  :4\n",
    "                }\n",
    "\n",
    "\n",
    "# Changing from object to integer the study program column \n",
    "survey_df['study program'] = [study_program[item] for item in survey_df['study program']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ethnicity Column\n",
    "############################################################################\n",
    "\n",
    "## Counting the total number of future Mackbook and Windows laptops\n",
    "# survey_df['ethnicity'].value_counts()\n",
    "\n",
    "\n",
    "# Dictionary to loop over ethnicity\n",
    "\n",
    "ethnicity = {\n",
    "             'White / Caucasian'    :1,\n",
    "             'Far east Asian'       :2,\n",
    "             'West Asian / Indian'  :3,\n",
    "             'Hispanic / Latino'    :4,\n",
    "             'Prefer not to answer' :5,\n",
    "             'African American'     :6,\n",
    "             'Middle Eastern'       :7,\n",
    "             'Native American'      :8,\n",
    "             'unknown'              :9}\n",
    "\n",
    "\n",
    "# Changing from object to integer the study program column \n",
    "survey_df['ethnicity'] = [ethnicity[item] for item in survey_df['ethnicity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for id without the letter in front\n",
    "split_id('ID',survey_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking that changes have been made\n",
    "# survey_df.head()\n",
    "# survey_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinking = {}\n",
    "# communicating = {'life of party',}\n",
    "# team building = {'little concern others  ',}\n",
    "# demographic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2> Dropping Demographics </h2><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling (normalizing) variables before correlation analysis\n",
    "\n",
    "# dropping demographic information\n",
    "\n",
    "purchase_behavior = survey_df.drop(['ID',\n",
    "                                    'nationality',\n",
    "                                    'current laptop',\n",
    "                                    'Gender',\n",
    "                                    'age',\n",
    "                                    'ethnicity',\n",
    "                                    'study program',\n",
    "                                    'id_new'],\n",
    "                                      axis = 1)\n",
    "\n",
    "##checking the data\n",
    "# purchase_behavior.info()\n",
    "# purchase_behavior.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(purchase_behavior)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(purchase_behavior)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "purchases_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "purchases_scaled.columns = purchase_behavior.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(purchase_behavior), '\\n\\n')\n",
    "print(pd.np.var(purchases_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h2> Scree Plot </h2><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = 10,\n",
    "          random_state = 222)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca = pca.fit_transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # naming each principal component\n",
    "# factor_loadings_3.columns = ['Thinking',\n",
    "#                              'Communicating',\n",
    "#                              '']\n",
    "\n",
    "\n",
    "# # checking the result\n",
    "# factor_loadings_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_3 = PCA(n_components = 2,\n",
    "            random_state = 222)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "customer_pca_3 = pca_3.fit_transform(purchases_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# printing the sum of all explained variance ratios\n",
    "print(pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### Max PC Model ###\n",
    "####################\n",
    "# transposing pca components (pc = MAX)\n",
    "factor_loadings = pd.DataFrame(pd.np.transpose(pca.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings = factor_loadings.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "##################\n",
    "### 3 PC Model ###\n",
    "##################\n",
    "# transposing pca components (pc = 3)\n",
    "factor_loadings_3 = pd.DataFrame(pd.np.transpose(pca_3.components_))\n",
    "\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_3 = factor_loadings_3.set_index(purchases_scaled.columns)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(f\"\"\"\n",
    "MAX Components Factor Loadings\n",
    "------------------------------\n",
    "{factor_loadings.round(2)}\n",
    "\n",
    "\n",
    "3 Components Factor Loadings\n",
    "------------------------------\n",
    "{factor_loadings_3.round(2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_3.columns = ['selfawareness_introvert',\n",
    "                             'thinking'\n",
    "#                              'organized_enthusiastic_problemsolving',\n",
    "#                             'communication_problemsolving',\n",
    "#                             'communication',\n",
    "#                             'team_leader_productive'\n",
    "                            ]\n",
    "\n",
    "\n",
    "# checking the result\n",
    "factor_loadings_3.round(4)\n",
    "#1feel blue, \n",
    "#2 listen carefully to others\n",
    "#3am exacting in my work, understand complex situations, don't generate new ideas\n",
    "#4communication - quiet around strangers\n",
    "#5good negotiator\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing factor strengths per customer\n",
    "X_pca_reduced = pca_3.transform(purchases_scaled)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "X_pca_df = pd.DataFrame(X_pca_reduced)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "X_pca_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h1> Part III: Clustering </h1><br>\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.np.var(X_pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(X_pca_df)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled_pca = scaler.transform(X_pca_df)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "pca_scaled = pd.DataFrame(X_scaled_pca)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "pca_scaled.columns = ['selfawareness_introvert',\n",
    "                             'thinking'\n",
    "#                              'Winers',\n",
    "#                             'B',\n",
    "#                             'C',\n",
    "#                             'D'\n",
    "                     ]\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(X_pca_df), '\\n\\n')\n",
    "print(pd.np.var(pca_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h1> Part IV: Agglomerative Clustering </h1><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y = purchases_scaled,\n",
    "                                 method = 'ward')\n",
    "\n",
    "\n",
    "# setting plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6)\n",
    "\n",
    "\n",
    "# saving and displaying the plot\n",
    "plt.savefig('standard_hierarchical_clust_ward.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the inertia_plot() function\n",
    "interia_plot(data = purchases_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a k-Means object with five clusters\n",
    "customers_k_pca = KMeans(n_clusters = 3,\n",
    "                         random_state = 222)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(purchases_scaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([customers_kmeans_pca,\n",
    "                         X_pca_df],\n",
    "                         axis = 1)\n",
    "\n",
    "\n",
    "# checking results\n",
    "clst_pca_df\n",
    "\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([survey_df.loc[ : , ['current laptop', 'future laptop']],\n",
    "                                clst_pca_df],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "final_pca_clust_df.columns = ['current laptop',\n",
    "                              'future laptop',\n",
    "                              'selfawareness_introvert',\n",
    "                             'component1',\n",
    "                              'component2'\n",
    "                              ]\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(final_pca_clust_df.head(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<h1> Part V: Analyze with Demographics </h1><br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming current laptop\n",
    "current_laptop = {1 :'Macbook',\n",
    "                  2 :'Windows laptop'}\n",
    "\n",
    "final_pca_clust_df['current laptop'].replace(current_laptop, inplace = True)\n",
    "\n",
    "\n",
    "# renaming future laptop\n",
    "future_laptop = {1 :'Macbook',\n",
    "                 2 :'Windows laptop',\n",
    "                 3 :'Chromebook'}\n",
    "\n",
    "final_pca_clust_df['future laptop'].replace(future_laptop, inplace = True)\n",
    "\n",
    "# # renaming study program\n",
    "# study_program = {1 :'DD(MIB & Business Analytics)',\n",
    "#                 2 :'One year Business Analytics',\n",
    "#                 3:'DD (MBA & Business Analytics)'}\n",
    "# final_pca_clust_df['study program'].replace(study_program, inplace = True)\n",
    "\n",
    "\n",
    "# #rename gender\n",
    "# gender = {1:'Male',\n",
    "#          2:'Female'}\n",
    "\n",
    "# final_pca_clust_df['Gender'].replace(gender, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# adding a productivity step\n",
    "data_df = final_pca_clust_df\n",
    "\n",
    "\n",
    "# checking results\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# current laptop\n",
    "########################\n",
    "\n",
    "# Herbivores\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x    = 'current laptop',\n",
    "            y    = 'component1',\n",
    "            hue  = 'selfawareness_introvert',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# current laptop\n",
    "########################\n",
    "\n",
    "# Herbivores\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x = 'future laptop',\n",
    "            y = 'component1',\n",
    "            hue = 'selfawareness_introvert',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "500px",
    "left": "1020.98px",
    "top": "109.722px",
    "width": "255.99px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
